{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ff47a2-96f7-4706-8393-52c5d2747ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.tabular.all import *\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c91daf7-fe7f-448b-a9e7-668a319b2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def export(self:TabularPandas, fname='export.pkl', pickle_protocol=2):\n",
    "    \"Export the contents of `self` without the items\"\n",
    "    old_to = self\n",
    "    self = self.new_empty()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        pickle.dump(self, open(Path(fname), 'wb'), protocol=pickle_protocol)\n",
    "        self = old_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2c93514-699e-43d8-849d-8ae5d07dce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_pth,is_train_ds=False):\n",
    "    \n",
    "    df = pd.read_csv(data_pth, low_memory=False)\n",
    "\n",
    "    with open('artifacts/features.txt') as json_file:\n",
    "            features = json.load(json_file)\n",
    "    \n",
    "    cont = features['cont']\n",
    "    cat = features['cat']\n",
    "    dep_var = features['dep_var']\n",
    "    cols = cat+cont+[dep_var]\n",
    "    \n",
    "    df = df[cols]\n",
    "    \n",
    "    if is_train_ds:\n",
    "        \n",
    "        procs_nn = [Categorify, FillMissing]\n",
    "        data_proc = TabularPandas(df, procs_nn, cat, cont, splits=None, y_names=dep_var)\n",
    "        data_proc.export('artifacts/data-proc.pkl')\n",
    "    \n",
    "    else:\n",
    "        with open('artifacts/data-proc.pkl', 'rb') as preproc_file:\n",
    "            preproc = pickle.load(preproc_file)\n",
    "\n",
    "            data_proc = preproc.train.new(df)\n",
    "            data_proc.process()\n",
    "    \n",
    "    X,y = data_proc.train.xs,data_proc.train.y\n",
    "    \n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c8a13e-ac04-4d83-9162-c2afe537d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_data('data/train-sample.csv',is_train_ds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2186eb5-da7c-48df-9436-5e074d86645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.drop(['TransactionDT'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d80a89d-1435-430e-a1c5-ee116be8c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = (y[y==0]).count() / (y[y==1]).count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "923a12ff-7ad1-4f76-bb2c-33b0e3393232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.571428571428573"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d294bf7-cd3f-4e88-aa93-bff85570a610",
   "metadata": {},
   "outputs": [],
   "source": [
    " params = {\n",
    "        # defines booster, gblinear for linear functions.\n",
    "        \"booster\": \"gbtree\",\n",
    "        # sampling ratio for training data.\n",
    "        \"subsample\": 0.8,\n",
    "        # sampling according to each tree.\n",
    "        \"colsample_bytree\": 0.7,\n",
    "        #number of trees\n",
    "        \"n_estimators\": 400,\n",
    "        # maximum depth of the tree, signifies complexity of the tree.\n",
    "        \"max_depth\": 14,\n",
    "        # minimum child weight, larger the term more conservative the tree.\n",
    "        \"min_child_weight\": 14,\n",
    "        \"learning_rate\": 0.0069,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"scale_pos_weight\": w\n",
    " }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45175d90-d21b-4699-aef8-68ac02a36d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e7e9f59-788f-4ccc-ad9b-12475384e269",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ieee/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "/opt/anaconda3/envs/ieee/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC: 0.722901554404145, Average Accuracy: 0.9488\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "accuracies = []\n",
    "#Create stratified folds to avoid our model overfitting. we create 5 folds for this model\n",
    "kf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "for idx in kf.split(X=X,y=y):\n",
    "    train_idx, valid_idx = idx[0], idx[1]\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid,  y_valid = X.iloc[valid_idx], y.iloc[valid_idx]\n",
    "\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        eval_metric='auc', \n",
    "        eval_set=[(X_valid, y_valid)], \n",
    "        verbose=False, \n",
    "        early_stopping_rounds = 100\n",
    "    )\n",
    "\n",
    "    predictions = model.predict(X_valid)\n",
    "\n",
    "\n",
    "    auc = roc_auc_score(y_valid, predictions)\n",
    "    aucs.append(auc)\n",
    "    accuracy = accuracy_score(y_valid, predictions)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "\n",
    "# calculate the average of metrics for all folds\n",
    "avg_auc = np.mean(aucs)\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "print(f'Average AUC: {avg_auc}, Average Accuracy: {avg_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f2ee736-9079-44c3-a510-b05ff10a1a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7236861584011843"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_valid)\n",
    "\n",
    "\n",
    "auc = roc_auc_score(y_valid, predictions)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ef7bd28-0853-4481-8690-56a1fdcba0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainerdashboard import ClassifierExplainer, InlineExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04cad988-508f-4f93-901d-477e60c0581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected XGBClassifier model: Changing class type to XGBClassifierExplainer...\n",
      "Note: model_output=='probability'. For XGBClassifier shap values normally get calculated against X_background, but paramater X_background=None, so using X instead\n",
      "Generating self.shap_explainer = shap.TreeExplainer(model, X, model_output='probability', feature_perturbation='interventional')...\n",
      "Note: Shap interaction values will not be available. If shap values in probability space are not necessary you can pass model_output='logodds' to get shap values in logodds without the need for a background dataset and also working shap interaction values...\n"
     ]
    }
   ],
   "source": [
    "explainer = ClassifierExplainer(model, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ba5ad83-234d-4175-bf94-8afe5a94b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = InlineExplainer(explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3df8808b-8ce8-44f3-bb31-a4bc77b7aef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ieee/lib/python3.8/site-packages/jupyter_dash/jupyter_app.py:139: UserWarning:\n",
      "\n",
      "The 'environ['werkzeug.server.shutdown']' function is deprecated and will be removed in Werkzeug 2.1.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"800\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1380a8730>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating shap values...\n"
     ]
    }
   ],
   "source": [
    "ie.importances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46d812c3-1cd5-4d83-8d18-c97fe1b8e50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|====                | 886/5000 [00:18<01:23]       "
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"800\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x138088bb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|=====               | 1290/5000 [00:26<01:14]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating roc auc curves...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|=====               | 1340/5000 [00:27<01:13]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating prediction probabilities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|==============      | 3486/5000 [01:09<00:29]       "
     ]
    }
   ],
   "source": [
    "ie.classifier.roc_auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9fff1bc2-bbf6-43b3-9075-17a8cf946d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|===============     | 3742/5000 [01:14<00:24]       /opt/anaconda3/envs/ieee/lib/python3.8/site-packages/jupyter_dash/jupyter_app.py:139: UserWarning:\n",
      "\n",
      "The 'environ['werkzeug.server.shutdown']' function is deprecated and will be removed in Werkzeug 2.1.\n",
      "\n",
      " 82%|================    | 4111/5000 [01:21<00:17]       "
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"800\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13807c130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|==================  | 4564/5000 [01:30<00:08]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating confusion matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 4983/5000 [01:38<00:00]        "
     ]
    }
   ],
   "source": [
    "ie.classifier.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee27d8-bb46-4242-aa06-c8ccb7d09089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
